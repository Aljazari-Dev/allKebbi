# rag_utils.py
import os
import re
from types import SimpleNamespace

import numpy as np
from docx import Document
from sentence_transformers import SentenceTransformer
from urllib.parse import unquote_plus

from app.config import SUBJECT_RAG_DIR, RAG_MODEL_NAME, RAG_TOP_K
from app.ai_utils import openai_chat_completion

# cache in-memory: key -> {"paragraphs": [...], "embeddings": np.ndarray}
SUBJECT_RAG_CACHE = {}

RAG_SYSTEM_PROMPT = """
Ø£Ù†Øª Ø±ÙˆØ¨ÙˆØª Ù…Ø¹Ù„Ù… Ù…ÙˆØ§Ø¯ Ø¹Ù„Ù…ÙŠØ© (Ù…Ø«Ù„ Ø§Ù„Ø£Ø­ÙŠØ§Ø¡ ÙˆØ§Ù„ÙƒÙŠÙ…ÙŠØ§Ø¡) Ù„Ø·Ù„Ø¨Ø© Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ Ø§Ù„Ù…ØªÙˆØ³Ø· ÙÙŠ Ø§Ù„Ø¹Ø±Ø§Ù‚.
Ø³ÙŠØªÙ… ØªØ²ÙˆÙŠØ¯Ùƒ Ø¨Ù…Ù‚Ø§Ø·Ø¹ Ù…Ù† ÙƒØªØ§Ø¨ Ù…Ø¯Ø±Ø³ÙŠ ÙˆØ³Ø¤Ø§Ù„ Ø·Ø§Ù„Ø¨.

Ø¯ÙˆØ±Ùƒ Ø£Ù† ØªØªØµØ±Ù‘Ù Ù…Ø«Ù„ Ø£Ø³ØªØ§Ø° ÙÙŠ Ø§Ù„ØµÙ ÙŠØ´Ø±Ø­ Ù„Ù„Ø·Ø§Ù„Ø¨ØŒ Ù„ÙƒÙ†:
- ÙƒÙ„ Ù…Ø§ ØªÙ‚ÙˆÙ„Ù‡ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø¨Ù†ÙŠØ§Ù‹ Ø­ØµØ±Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹.
- Ù„Ø§ ÙŠÙØ³Ù…Ø­ Ù„Ùƒ Ø¨Ø§Ø®ØªØ±Ø§Ø¹ Ø­Ù‚Ø§Ø¦Ù‚ Ø¬Ø¯ÙŠØ¯Ø© Ø£Ùˆ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø²ÙˆÙ‘ÙØ¯Ø©.

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ù‡Ù…Ø©:
1- Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø¹Ù† Ø§Ù„Ø¬Ù…Ù„Ø© Ø£Ùˆ Ø§Ù„ÙÙ‚Ø±Ø© Ø§Ù„ØªÙŠ ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø±.
2- Ø­Ø±Ù‘Ø± Ø§Ù„Ø¬ÙˆØ§Ø¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø¹Ù„Ù… ÙŠØ´Ø±Ø­ Ù„Ø·Ù„Ø§Ø¨Ù‡:
   - Ø§Ø³ØªØ¹Ù…Ù„ Ø¬Ù…Ù„Ø§Ù‹ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ‚ØµÙŠØ±Ø©.
   - ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¨Ø³ÙŠØ· Ø§Ù„Ù„ØºØ© Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¬Ù…Ù„.
   - ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¯Ù…Ø¬ Ø¨ÙŠÙ† Ø¬Ù…Ù„ Ù…ØªÙØ±Ù‚Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ù…Ø§ Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ù†Ù‰ Ù†ÙØ³Ù‡.
3- ØªØ¬Ù†Ù‘Ø¨ Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³ Ø§Ù„Ø­Ø±ÙÙŠ Ø§Ù„Ø·ÙˆÙŠÙ„ Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨Ø› Ø¥Ù† Ø§Ø­ØªØ¬Øª Ø§Ù‚ØªØ¨Ø§Ø³Ø§Ù‹ Ø­Ø±ÙÙŠØ§Ù‹ ÙÙ„ÙŠÙƒÙ† Ù‚ØµÙŠØ±Ø§Ù‹ (ØªØ¹Ø±ÙŠÙ Ø£Ùˆ Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©).
4- Ù„Ø§ ØªØ¹ÙØ¯ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠ Ø§Ù„Ø¬ÙˆØ§Ø¨ØŒ ÙˆÙ„Ø§ ØªØ°ÙƒØ± Ø±Ù‚Ù… Ø§Ù„ÙÙ‚Ø±Ø© Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„ÙƒØªØ§Ø¨ Ø£Ùˆ Ø£ÙŠ ØªÙØ§ØµÙŠÙ„ ØªÙ‚Ù†ÙŠØ©.
5- Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ø¬ÙˆØ§Ø¨ ÙˆØ§Ø¶Ø­Ø§Ù‹ ÙÙŠ Ø§Ù„Ù†ØµØŒ Ù‚Ù„ Ø­Ø±ÙÙŠØ§Ù‹:
"Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø¥ÙŠØ¬Ø§Ø¯ Ø¬ÙˆØ§Ø¨ Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨."
6- Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ù…Ø¨Ø³Ø·Ø©ØŒ ÙˆØ¨Ø¥ÙŠØ¬Ø§Ø² (Ù…Ù† 2 Ø¥Ù„Ù‰ 5 Ø¬Ù…Ù„)ØŒ ÙˆÙƒØ£Ù†Ùƒ ØªØ´Ø±Ø­ Ù„Ø·Ù„Ø¨Ø© Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ Ø§Ù„Ù…ØªÙˆØ³Ø·.
"""

print("ğŸ”§ Loading RAG embedding model...")
try:
    RAG_EMBED_MODEL = SentenceTransformer(RAG_MODEL_NAME)
except Exception as e:
    print("âš ï¸ RAG feature disabled (embedding model load error):", e)
    RAG_EMBED_MODEL = None


def subject_rag_key(stage, section, subject):
    return f"{stage}|||{section}|||{subject}"


def subject_book_paths(stage, section, subject):
    safe_stage = re.sub(r"[^A-Za-z0-9]+", "_", stage)
    safe_section = re.sub(r"[^A-Za-z0-9]+", "_", section)
    safe_subject = re.sub(r"[^A-Za-z0-9]+", "_", subject)
    base = f"{safe_stage}_{safe_section}_{safe_subject}".strip("_")
    docx_path = os.path.join(SUBJECT_RAG_DIR, base + ".docx")
    cleaned_path = os.path.join(SUBJECT_RAG_DIR, base + "_cleaned.txt")
    return docx_path, cleaned_path


def subject_book_exists(stage, section, subject):
    docx_path, _ = subject_book_paths(stage, section, subject)
    return os.path.exists(docx_path)


def rag_embed_texts(texts, is_query=False):
    if RAG_EMBED_MODEL is None:
        raise RuntimeError("RAG embedding model is not available on this server.")
    prefix = "query: " if is_query else "passage: "
    return RAG_EMBED_MODEL.encode(
        [prefix + t for t in texts],
        normalize_embeddings=True
    )


def load_subject_book_into_memory(stage, section, subject):
    """
    ØªØ­Ù…ÙŠÙ„ ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© (Word) Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§Ø¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‚Ø±Ø§Øª + embeddings.
    """
    key = subject_rag_key(stage, section, subject)
    docx_path, cleaned_path = subject_book_paths(stage, section, subject)
    if not os.path.exists(docx_path):
        return False, "Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ ÙƒØªØ§Ø¨ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§Ø¯Ø© Ø­ØªÙ‰ Ø§Ù„Ø¢Ù†."

    if os.path.exists(cleaned_path):
        with open(cleaned_path, "r", encoding="utf-8") as f:
            book_text = f.read()
    else:
        print(f"ğŸ“– Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Word Ù„Ù„Ù…Ø§Ø¯Ø© {stage}/{section}/{subject}: {docx_path}")
        doc = Document(docx_path)
        text = "\n".join(p.text for p in doc.paragraphs)

        text = re.sub(r"[Ù€]+", "", text)
        text = re.sub(r"\s+", " ", text)
        text = re.sub(r"Ø§Ø§Ù„", "Ø§Ù„", text)
        text = re.sub(r"\s*([ØŒØ›:.ØŸ])\s*", r"\1 ", text)
        text = re.sub(r"(?<![\.\ØŸ!])\n+", ". ", text)
        text = text.strip()

        sentences = re.split(r"(?<=[\.ØŸ!])\s+", text)
        paragraphs = []
        temp = []
        for s in sentences:
            if not s.strip():
                continue
            temp.append(s.strip())
            if len(temp) >= 3:
                paragraphs.append(" ".join(temp))
                temp = []
        if temp:
            paragraphs.append(" ".join(temp))

        cover = f"{stage} / {section} / {subject}\n\n"
        book_text = cover + "\n\n".join(paragraphs)

        with open(cleaned_path, "w", encoding="utf-8") as f:
            f.write(book_text)

    paragraphs = [p.strip() for p in re.split(r"\n{2,}", book_text) if p.strip()]
    if not paragraphs:
        return False, "Ø§Ù„ÙƒØªØ§Ø¨ ÙØ§Ø±Øº Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ù„Ù."

    try:
        para_embeddings = rag_embed_texts(paragraphs, is_query=False).astype("float32")
    except Exception as e:
        return False, f"Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ embeddings: {e}"

    SUBJECT_RAG_CACHE[key] = {
        "paragraphs": paragraphs,
        "embeddings": para_embeddings,
    }
    print(f"ğŸ“˜ RAG book loaded for {stage}/{section}/{subject}: {len(paragraphs)} ÙÙ‚Ø±Ø©.")
    return True, None


def retrieve_top_k_for_subject(question, stage, section, subject, k=RAG_TOP_K):
    key = subject_rag_key(stage, section, subject)
    if key not in SUBJECT_RAG_CACHE:
        ok, err = load_subject_book_into_memory(stage, section, subject)
        if not ok:
            return [], err
    data = SUBJECT_RAG_CACHE[key]
    paragraphs = data["paragraphs"]
    embeddings = data["embeddings"]
    q_emb = rag_embed_texts([question], is_query=True)[0].astype("float32")
    scores = np.dot(embeddings, q_emb)
    idx = np.argsort(-scores)[:k]
    results = [(int(i), float(scores[i]), paragraphs[i]) for i in idx]
    return results, None


def subject_rag_answer(question, stage, section, subject):
    """
    Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ GPT Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ù…Ù† ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯ ÙÙ‚Ø·.
    """
    retrieved, err = retrieve_top_k_for_subject(question, stage, section, subject, k=RAG_TOP_K)
    if err:
        return None, [], err

    context_blocks = []
    for idx, score, text in retrieved:
        context_blocks.append(f"[ÙÙ‚Ø±Ø© {idx}] {text}")
    context_str = "\n\n".join(context_blocks)

    prompt = f"""
Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ù† Ø§Ù„Ø·Ø§Ù„Ø¨:
{question}

Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨ (Ù‡Ø°Ù‡ Ù„Ù„Ù…Ø±Ø¬Ø¹ ÙÙ‚Ø·ØŒ Ù„Ø§ ØªØ¹ÙØ¯ Ø¥Ø±Ø³Ø§Ù„Ù‡Ø§ Ù„Ù„Ø·Ø§Ù„Ø¨ ÙƒÙ…Ø§ Ù‡ÙŠ):
{context_str}

Ø£Ø¹Ø·Ù Ø¬ÙˆØ§Ø¨Ùƒ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø·Ø§Ù„Ø¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø¹Ù„Ù… ÙŠØ´Ø±Ø­ Ø§Ù„Ø¯Ø±Ø³ØŒ Ù…Ù„ØªØ²Ù…Ø§Ù‹ Ø¨Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙÙŠ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù….
"""

    answer, api_err = None, None
    try:
        answer, api_err = openai_chat_completion(RAG_SYSTEM_PROMPT, prompt)
    except Exception as e:
        api_err = str(e)

    if api_err:
        return None, retrieved, api_err
    return (answer or "").strip(), retrieved, None


def save_uploaded_book(file_storage, stage, section, subject):
    """
    ØªØ³ØªØ¹Ù…Ù„ ÙÙŠ ØµÙØ­Ø© Ø§Ù„ÙˆÙŠØ¨ Ù„Ø±ÙØ¹ / Ø§Ø³ØªØ¨Ø¯Ø§Ù„ ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø©.
    """
    docx_path, cleaned_path = subject_book_paths(stage, section, subject)
    os.makedirs(os.path.dirname(docx_path), exist_ok=True)
    file_storage.save(docx_path)
    if os.path.exists(cleaned_path):
        os.remove(cleaned_path)
    key = subject_rag_key(stage, section, subject)
    if key in SUBJECT_RAG_CACHE:
        del SUBJECT_RAG_CACHE[key]
    ok, err = load_subject_book_into_memory(stage, section, subject)
    return ok, err


def run_book_rag(stage, section, subject, question, lang="ar-SA"):
    """
    Ø¯Ø§Ù„Ø© ÙˆØ³ÙŠØ·Ø© ØªØ´ØºÙ‘Ù„ RAG Ø¹Ù„Ù‰ ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙÙ‚Ø·.
    ØªØ±Ø¬Ø¹ Ù†ØµÙ‘ Ø§Ù„Ø¬ÙˆØ§Ø¨ Ø§Ù„Ø¬Ø§Ù‡Ø² Ù„Ù„Ø·Ø§Ù„Ø¨.
    """
    stage = unquote_plus(stage)
    section = unquote_plus(section)
    subject = unquote_plus(subject)

    question = (question or "").strip()
    if not question:
        return "Ù„Ù… Ø£ÙÙ‡Ù… Ø³Ø¤Ø§Ù„ÙƒØŒ Ø­Ø§ÙˆÙ„ Ø£Ù† ØªÙƒØªØ¨ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø´ÙƒÙ„ Ø£ÙˆØ¶Ø­."

    if not subject_book_exists(stage, section, subject):
        return "Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ ÙƒØªØ§Ø¨ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§Ø¯Ø© Ø¨Ø¹Ø¯."

    answer, retrieved, err = subject_rag_answer(question, stage, section, subject)
    if err:
        print("RAG error:", err)
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø®Ø§Ø¯Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒØªØ§Ø¨ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ù„Ø§Ø­Ù‚Ø§Ù‹."

    if not (answer or "").strip():
        return "Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø¥ÙŠØ¬Ø§Ø¯ Ø¬ÙˆØ§Ø¨ ÙˆØ§Ø¶Ø­ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¯Ø§Ø®Ù„ Ø§Ù„ÙƒØªØ§Ø¨."

    return (answer or "").strip()


def wrap_contexts(retrieved):
    return [
        SimpleNamespace(index=idx, score=score, text=text)
        for idx, score, text in retrieved
    ]
